{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.243331Z",
     "start_time": "2024-08-01T17:46:22.473598Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install scipy\n",
    "# !pip install torch\n",
    "# !pip install matplotlib\n",
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4fbc6b56b8cbae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.274764Z",
     "start_time": "2024-08-01T17:46:22.475263Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80a1147c4c0a6f95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.274897Z",
     "start_time": "2024-08-01T17:46:24.148740Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "gpu = torch.device(\"cuda:0\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "\n",
    "# Use smaller network for testing - ex 2000 neurons\n",
    "# Even for the project, doing it for 10^6 neurons would take too long\n",
    "# Problem this creates: test network is denser than actual network b/c we have 10^3 neurons but 10^2 connections per neuron\n",
    "num_neurons = 2000\n",
    "num_i = int(0.1 * num_neurons)\n",
    "num_e = int(0.9 * num_neurons)\n",
    "\n",
    "# Epsilon value close to 0 to prevent nan in division by 0\n",
    "eps = 1e-6\n",
    "\n",
    "# Num excitatory inputs and inhibitory inputs to each neuron (in reality it should be 500 but we reduce it here to make things faster)\n",
    "k = 100\n",
    "\n",
    "# Number of olfactory bulb channels (glomeruli) to each neuron\n",
    "D = 10 ** 3\n",
    "# For each neuron, how many glomeruli inputs it receives (should be 10^2)\n",
    "num_channel_inputs = 100\n",
    "\n",
    "# Number of odors\n",
    "P = 16\n",
    "# Novel activity is up to P // 2, and familiar activity is after\n",
    "novel_inds = torch.arange(0, P // 2)\n",
    "familiar_inds = torch.arange(P // 2, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4e13c61f25818ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.274933Z",
     "start_time": "2024-08-01T17:46:24.155175Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creates sparse adjacency matrix with the given probability of edge connection and size mxn\n",
    "def create_adj_matrix(p, m, n):\n",
    "    # num_connections = int(p * m * n)\n",
    "    # m_coords = torch.randint(0, m, (num_connections,))\n",
    "    # n_coords = torch.randint(0, n, (num_connections,))\n",
    "    # indices = torch.vstack((m_coords, n_coords))\n",
    "    # values = torch.ones(num_connections)\n",
    "    # A_mn = torch.sparse_coo_tensor(indices, values, (m, n))\n",
    "    probs = torch.ones(m, n) * p\n",
    "    A_mn = torch.bernoulli(probs)\n",
    "    return A_mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6b94961ca601610",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.274966Z",
     "start_time": "2024-08-01T17:46:24.159685Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# New way of generating correlations between odors: we want different sets of odors to be correlated differently, so that when we subtract each neuron's mean activity over odors, it doesn't cancel out the variation between odors (if all the odors are correlated the same, they will tend to produce similar values for a single neuron and therefore subtracting by the mean will remove these values and only leave small fluctuations)\n",
    "# So we sample a small set of odors P' and make them linearly independent, and then by multiplying by a P'x P gaussian matrix we project into mitral cell activity space for all P odors, basically making the P odors a linear combination of the set of P' odors (the smaller P' is, the more correlated the resulting set of P odors will be)\n",
    "# We also scale the variance depending on how small P' is, so we will maintain differently correlated odors, just with higher total correlation if P' is small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28887b0933bdd67a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.274997Z",
     "start_time": "2024-08-01T17:46:24.162068Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P_prime = 4\n",
    "def correlated_mitral_activity():\n",
    "    # Each of the P' odors is independent (correlation of 0)\n",
    "    sigma_p_prime = torch.zeros((P_prime, P_prime)).fill_diagonal_(1)\n",
    "    dist = torch.distributions.MultivariateNormal(torch.zeros(P_prime), sigma_p_prime)\n",
    "    p_prime_activity = dist.sample(torch.Size([D]))\n",
    "    var = 1 / P_prime\n",
    "    projection = torch.normal(torch.zeros((P_prime, P)), torch.ones(P_prime, P) * np.sqrt(var))\n",
    "    activity = p_prime_activity @ projection\n",
    "    return activity.to(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67da2d3fe4b6a081",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.275027Z",
     "start_time": "2024-08-01T17:46:24.167675Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Takes in mitral activity I and computes feedforward activity h_bar_ff\n",
    "def compute_feedforward_activity(I):\n",
    "    # Probability that a channel weight will be nonzero\n",
    "    p = num_channel_inputs / D\n",
    "    # Only the first 0.9 * n rows should have this bernoulli number, the rest should be 0 b/c they don't receive a channel input\n",
    "    # Check whether each neuron still receives ~10^2 nonzero inputs or what the distribution actually looks like\n",
    "    # Because when we calculate the adjacency matrix we don't go by row (e.g ensuring each neuron has these ~10^2 connections)\n",
    "    # Alternative: sample from Binomial distribution w/ mean 100\n",
    "    # The output n for each row is the number of nonzero inputs, and you choose a random subset n of the indices for that row and make them 1\n",
    "    with torch.device(gpu):\n",
    "        a = create_adj_matrix(p, num_e, D)\n",
    "        # Inhibitory neurons don't receive channel input\n",
    "        # This is the first simplification, where we neglect the first inhibitory layer I_ff\n",
    "        b = torch.zeros(size=(num_i, D))\n",
    "        W_ff = torch.cat(tensors=(a, b), dim=0)\n",
    "        \n",
    "        h_ff = (W_ff @ I) * (1 / np.sqrt(num_channel_inputs))\n",
    "        h_bar_ff = torch.zeros_like(h_ff)\n",
    "        h_bar_ff[:num_e] = h_ff[:num_e] - torch.mean(h_ff[:num_e], dim=0, keepdim=True)\n",
    "    return h_bar_ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b23d7ccb6f4b0787",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.275058Z",
     "start_time": "2024-08-01T17:46:24.170963Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_initial_recurrent_weights():\n",
    "    k_ee = k_ei = k_ie = k_ii = k\n",
    "    #p_ee = k_ee / num_e\n",
    "    # k inhibitory inputs to that e neuron, out of num_i total inhibitory neurons gives the connection probability per neuron\n",
    "    p_ei = k_ei / num_i\n",
    "    p_ie = k_ie / num_e\n",
    "    #p_ii = k_ii / num_i\n",
    "    \n",
    "    # Constants\n",
    "    #w_ee = 0.1\n",
    "    w_ei = 0.2\n",
    "    w_ie = 0.5\n",
    "    #w_ii = 0.3\n",
    "    # Ignore ee and ii weights for now:\n",
    "    p_ee = p_ii = w_ee = w_ii = 0\n",
    "    with torch.device(gpu):\n",
    "        W_ee = create_adj_matrix(p_ee, num_e, num_e) * w_ee\n",
    "        W_ei = create_adj_matrix(p_ei, num_e, num_i) * -w_ei\n",
    "        W_ie = create_adj_matrix(p_ie, num_i, num_e) * w_ie\n",
    "        W_ii = create_adj_matrix(p_ii, num_i, num_i) * -w_ii\n",
    "        \n",
    "        # Concat\n",
    "        W_1 = torch.cat(tensors=(W_ee, W_ei), dim=1)\n",
    "        W_2 = torch.cat(tensors=(W_ie, W_ii), dim=1)\n",
    "        W_rec = torch.cat(tensors=(W_1, W_2), dim=0)\n",
    "    \n",
    "    return W_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65ae3fd6edb6a55b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.275088Z",
     "start_time": "2024-08-01T17:46:24.176889Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Computes activation threshold for neurons, based on the standard deviation of their firing rates across odors\n",
    "# This average standard deviation, multiplied by theta=2, ensures that each neuron will fire for only 5% of odors\n",
    "def compute_threshold(total_input, theta):\n",
    "    # For now, use diff thresholds for each neuron\n",
    "    center = torch.mean(total_input, dim=1, keepdim=True)\n",
    "    shift = torch.std(total_input, dim=1, keepdim=True)\n",
    "    threshold = center + (theta * shift)\n",
    "    # Since inhibitory neurons are linear\n",
    "    threshold[num_e:, :] = 0\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce5f8670e8cb95e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.275118Z",
     "start_time": "2024-08-01T17:46:24.180482Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ReLU for excitatory, linear for inhibitory\n",
    "def neuron_activations(X):\n",
    "    # Mask to keep excitatory\n",
    "    mask1 = torch.ones((num_neurons, 1), device=gpu)\n",
    "    mask1[num_e:, :] = 0\n",
    "    # Mask to keep inhibitory\n",
    "    mask2 = torch.zeros((num_neurons, 1), device=gpu)\n",
    "    mask2[num_e:, :] = 1\n",
    "    activation = (torch.relu(X) * mask1) + (X * mask2)\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14aa733bbbadf1db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.275148Z",
     "start_time": "2024-08-01T17:46:24.186449Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Computes R for each odor, with the activation threshold theta\n",
    "def compute_piriform_response(h_bar_ff, W_rec, threshold_mult):\n",
    "    # The coefficient of x_bar\n",
    "    tau = 1\n",
    "    # time step\n",
    "    dt = 0.1\n",
    "    # Number of time steps\n",
    "    T = 200\n",
    "    \n",
    "    # Initial condition where states are gaussian\n",
    "    mu_0 = 0.\n",
    "    sigma_0 = 0.2\n",
    "    X_0 = torch.normal(mu_0, sigma_0, size=(num_neurons, P))\n",
    "    X = X_0\n",
    "    X = X.to(gpu)\n",
    "    \n",
    "    #pts = []\n",
    "    for i in range(T-4):\n",
    "        with torch.no_grad():\n",
    "            part1 = -1 * X\n",
    "            part2 = (W_rec @ neuron_activations(X)) * (1 / np.sqrt(k))\n",
    "            part3 = h_bar_ff\n",
    "            dXdt = (1 / tau) * (part1 + part2 + part3)\n",
    "            X = X + (dXdt * dt)\n",
    "        # Look at convergence pattern for first odor, assuming that it'll\n",
    "        # be similar across odors (since they are all independent)\n",
    "        #pts.append(torch.mean(dXdt, dim=0)[0].item())\n",
    "   \n",
    "    # On the last 2 iterations only, track the gradient\n",
    "    # TODO increased to 4 just for more coverage\n",
    "    X.requires_grad_(True)\n",
    "    \n",
    "    for j in range(4):\n",
    "        part1 = -1 * X\n",
    "        part2 = (W_rec @ neuron_activations(X)) * (1 / np.sqrt(k))\n",
    "        part3 = h_bar_ff\n",
    "        dXdt = (1 / tau) * (part1 + part2 + part3)\n",
    "        X = X + (dXdt * dt)\n",
    "    \n",
    "    # The total input to the neuron at this last time step (should be equivalent to the resulting value of X after this time step, since dxdt = 0 after the recurrent network converges)\n",
    "    total_input = part2 + part3\n",
    "    threshold = compute_threshold(total_input, threshold_mult)\n",
    "    \n",
    "    # Plot derivatives to see if state converged\n",
    "    # plt.plot(torch.arange(T-2), pts)\n",
    "    # plt.show()\n",
    "    R = neuron_activations(X - threshold)\n",
    "    \n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "defc0132008cbd72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.275177Z",
     "start_time": "2024-08-01T17:46:24.189623Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute dimensionality of activity matrix R for either novel or familiar\n",
    "# def compute_dim(R, odor_inds):\n",
    "#     # Only compute for the excitatory neurons (b/c those are the ones that send signals to rest of brain\n",
    "#     C = torch.cov(R[:num_e, odor_inds[0]:odor_inds[-1]])\n",
    "#     dim = torch.trace(C) ** 2 / torch.trace(C @ C)\n",
    "#     return dim\n",
    "\n",
    "# trace() is invariant for cyclic permutations of a matrix\n",
    "# Since C is symmetric, it can be orthogonally diagonalized into UDU^T where U is composed of orthonormal eigenvectors, U^T = U^-1, and D is a diagonal matrix of eigenvalues\n",
    "# therefore, trace(C) = trace(UDU^T) = trace(DU^TU) = trace(D) = sum(eigvals of C)\n",
    "# Similarly for the denominator, we need to compute the sum of the squared eigenvalues, which is trace(D^2). trace(D^2) = trace(D^2U^TU) = trace(UD^2U^T) = trace((UDU^T)^2)) [by the property of matrix exponentiation for a diagonalizable matrix] = trace(C^2) = trace(C @ C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24911045583425aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.275393Z",
     "start_time": "2024-08-01T17:46:24.224277Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def create_model() -> torch.nn.Sequential:\n",
    "    # Number of neurons in hidden layer\n",
    "    hidden_size = 100\n",
    "    # Constrain output to certain values: nn.Hardtanh(-1, 1)\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(2, hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_size, 1),\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1cd6e5a0aa03ae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.275425Z",
     "start_time": "2024-08-01T17:46:24.228522Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start and stop indices for the section of W_rec we want to update, respectively \n",
    "# Takes in R matrix (neuron responses for each odor and tuple of update inds representing ie, then ei (each element in that tuple is itself a tuple of (post, pre))\n",
    "def compute_updates(R: torch.Tensor, models: tuple, update_inds: tuple) -> torch.Tensor:\n",
    "    # Compute the same pairs of R_i and R_j for every odor, per model\n",
    "    all_updates = []\n",
    "    for i in range(len(models)):\n",
    "        postsyn_responses = R[update_inds[i][0], :]\n",
    "        presyn_responses = R[update_inds[i][1], :]\n",
    "        model_input = torch.stack(tensors=(presyn_responses, postsyn_responses), dim=2).transpose(1, 0)\n",
    "        updates_per_odor = models[i](model_input)\n",
    "        model_updates = torch.mean(updates_per_odor, dim=0).squeeze(dim=1)\n",
    "        all_updates.append(model_updates)\n",
    "    \n",
    "    return all_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f51d515fadf0381",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.275457Z",
     "start_time": "2024-08-01T17:46:24.232958Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ie_post = (num_e, num_neurons)\n",
    "# ie_pre = (0, num_e)\n",
    "# ei_post = (0, num_e)\n",
    "# ei_pre = (num_e, num_neurons)\n",
    "# ie_update_inds = get_update_inds(ie_post, ie_pre, W_random)\n",
    "# ei_update_inds = get_update_inds(ei_post, ei_pre, W_random)\n",
    "# # (16, 19953, 2) -> (16, 19953)\n",
    "# a1, a2 = compute_updates(R_random.to(gpu), (ie_model, ei_model), (ie_update_inds, ei_update_inds))\n",
    "# #print(a1.shape, a2.shape)\n",
    "# print(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8887e40e8a4d89c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.275488Z",
     "start_time": "2024-08-01T17:46:24.235295Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def odor_corrs(R):\n",
    "    # We don't care about the actual responses per odor, just about a neuron's fluctuations around its mean response across odors\n",
    "    R_adjusted = R[:num_e] - torch.mean(R[:num_e], dim=1, keepdim=True)\n",
    "    # Each odor becomes a variable, because we want to calculate correlations between them across neurons\n",
    "    R_adjusted.t_()\n",
    "    # Like cov but divides by standard deviations, effectively normalizing the values (the diagonals of the resulting matrix become 1)\n",
    "    corrcoefs = torch.corrcoef(R_adjusted)\n",
    "    # If the responses are 0, variances across neurons will be 0, so denominator of corrcoef is 0, so term becomes nan\n",
    "    # In this case, the responses are \"perfectly correlated\" (bc always same value of 0) so its maximum correlation\n",
    "    # TODO do we need to change this NaN formulation so we propagate grad correctly?\n",
    "    corrcoefs = torch.nan_to_num(corrcoefs, nan=1.0)\n",
    "    # We only care about the correlations between the familiar odors\n",
    "    familiar_corrs = corrcoefs[P//2:P, P//2:P] - torch.eye(P // 2, device=gpu)\n",
    "    corr_sum = torch.sum(familiar_corrs ** 2)\n",
    "    avg_corr = torch.mean(torch.abs(familiar_corrs))\n",
    "    \n",
    "    return corr_sum, avg_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4d37265e0e371e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.275519Z",
     "start_time": "2024-08-01T17:46:24.241695Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sparsity per odor, across all (E) neurons\n",
    "def sparsity_per_odor(R):\n",
    "    # Epsilon for if we have zero responses\n",
    "    eps = 1e-6\n",
    "    sp_per_odor = 1 - ((torch.sum(R[:num_e], dim=0) ** 2 + eps) / (num_e * (torch.sum(R[:num_e] ** 2, dim=0)) + eps))\n",
    "    # Sparsity nan means that the responses were all 0 for an odor, meaning that its max sparsity of 1\n",
    "    return sp_per_odor\n",
    "\n",
    "# Sparsity per (E) neuron, across a given odor family\n",
    "def sparsity_per_neuron(R, odor_inds):\n",
    "    sp_per_neuron = 1 - (\n",
    "                (torch.sum(R[:num_e, odor_inds], dim=1) ** 2) / ((P // 2) * torch.sum(R[:num_e, odor_inds] ** 2, dim=1)))\n",
    "    return sp_per_neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1003ae68e7009d39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.275588Z",
     "start_time": "2024-08-01T17:46:24.248644Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try to minimize the correlations between values\n",
    "def loss_fn(R, lambda_corr, lambda_mu, lambda_var, lambda_sp, do_print=True):\n",
    "    corr_sum, avg_corr = odor_corrs(R)\n",
    "    corr_loss = (1 / P) * corr_sum\n",
    "    corr_term = lambda_corr * corr_loss\n",
    "    \n",
    "    means = torch.mean(R[:num_e], dim=0)\n",
    "    means_novel = torch.mean(means[novel_inds])\n",
    "    means_familiar = torch.mean(means[familiar_inds])\n",
    "    if torch.abs(means_novel + means_familiar) < eps:\n",
    "        # All means are the same so there's technically no loss\n",
    "        mu_term = 0\n",
    "    else:\n",
    "        mu_term = lambda_mu * (((means_familiar - means_novel + eps) / (means_novel + means_familiar)) ** 2)\n",
    "    \n",
    "    vars = torch.var(R[:num_e], dim=0)\n",
    "    var_novel = torch.mean(vars[novel_inds])\n",
    "    var_familiar = torch.mean(vars[familiar_inds])\n",
    "    if torch.abs(var_novel + var_familiar) < eps:\n",
    "        # All variances are the same so there's technically no loss\n",
    "        var_term = 0\n",
    "    else:\n",
    "        var_term = lambda_var * (((var_familiar - var_novel) / (var_novel + var_familiar)) ** 2)\n",
    "    \n",
    "    sparsities = sparsity_per_odor(R)\n",
    "    spars_novel = torch.mean(sparsities[novel_inds])\n",
    "    spars_familiar = torch.mean(sparsities[familiar_inds])\n",
    "    if torch.abs(spars_novel + spars_familiar) < eps:\n",
    "        # Sparsities are technically the same so the term shouldn't contribute to loss\n",
    "        spars_term = 0\n",
    "    else:\n",
    "        spars_term = lambda_sp * (((spars_familiar - spars_novel) / (spars_novel + spars_familiar)) ** 2)\n",
    "    \n",
    "    if do_print:\n",
    "        print(\"Avg Corr: %.4f, Corr: %.4f, Mu: %.4f, Var: %.4f, Sparsity: %.4f\" % (avg_corr, corr_term, mu_term, var_term, spars_term))\n",
    " \n",
    "    loss = corr_term + mu_term + var_term + spars_term\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7e8cc5982ed854c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.275650Z",
     "start_time": "2024-08-01T17:46:24.251548Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Detaching vs zero grad - should detach because we have a term dependent on the previous model iteration which isn't zero but some constant gradient, accumulated from that model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1252ae4977d8dbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.275684Z",
     "start_time": "2024-08-01T17:46:24.260339Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loss_after_odors(ie_model: torch.nn.Sequential, ei_model: torch.nn.Sequential, ie_update_inds, ei_update_inds, W_rec: torch.Tensor, R_current: torch.Tensor, h_bar_ff: torch.Tensor, threshold_mult, plasticity_ie, plasticity_ei, weight_decay_rate, weight_range: tuple, lambda_corr, lambda_mu, lambda_var, lambda_sp, detach_grad=True, with_loss=False):\n",
    "   # First, compute the respective weight updates through the novel and familiar odors from the current neural responses (which are from the current weight matrix)\n",
    "    \n",
    "    W_rec.requires_grad_(True)\n",
    "    \n",
    "    # TODO new paradigm: computing updates across odors and between models in parallel\n",
    "    # TODO regularize by penalizing high model update?\n",
    "    ie_model_updates, ei_model_updates = compute_updates(R_current, (ie_model, ei_model), (ie_update_inds, ei_update_inds))\n",
    "   \n",
    "    # with torch.no_grad():\n",
    "    #     val_tensor = ((1 - plasticity_rate * weight_decay_rate) * W_rec[update_inds]) + updates + (plasticity_rate * odor_update)\n",
    "    #     condition = torch.logical_and(torch.gt(val_tensor, min_weight), torch.le(val_tensor, max_weight))\n",
    "    \n",
    "    ie_updates = plasticity_ie * (ie_model_updates - weight_decay_rate * W_rec[ie_update_inds])\n",
    "    ei_updates = plasticity_ei * (ei_model_updates - weight_decay_rate * W_rec[ei_update_inds])\n",
    "    \n",
    "    ie_cond = torch.logical_and(torch.ge(W_rec[ie_update_inds] + ie_updates, weight_range[0][ie_update_inds]), torch.le(W_rec[ie_update_inds] + ie_updates, weight_range[1][ie_update_inds]))\n",
    "    ei_cond = torch.logical_and(torch.ge(W_rec[ei_update_inds] + ei_updates, weight_range[0][ei_update_inds]), torch.le(W_rec[ei_update_inds] + ei_updates, weight_range[1][ei_update_inds]))\n",
    "    \n",
    "    # TODO clamping updates instead of the weights post-update - change in gradient?\n",
    "    # TODO if we clamp to bounds then we'll see changes in correlation, b/c there is a change in weight instead of none at all\n",
    "    ie_bounded_updates = torch.where(ie_cond, ie_updates, 0)\n",
    "    ei_bounded_updates = torch.where(ei_cond, ei_updates, 0)\n",
    "   \n",
    "    # TODO penalize model for causing weight to go over threshold\n",
    "    # Amount below min\n",
    "    ie_a = torch.relu(weight_range[0][ie_update_inds] - (W_rec[ie_update_inds] + ie_updates))\n",
    "    # Amount above max\n",
    "    ie_b = torch.relu((W_rec[ie_update_inds] + ie_updates) - weight_range[1][ie_update_inds])\n",
    "    ie_over_weight = torch.sum(ie_a + ie_b) / len(ie_update_inds)\n",
    "    ei_a = torch.relu(weight_range[0][ei_update_inds] - (W_rec[ei_update_inds] + ei_updates))\n",
    "    # Amount above max\n",
    "    ei_b = torch.relu((W_rec[ei_update_inds] + ei_updates) - weight_range[1][ei_update_inds])\n",
    "    ei_over_weight = torch.sum(ei_a + ei_b) / len(ei_update_inds)\n",
    "    \n",
    "    #W_rec = W_rec.clamp(min=weight_range[0], max=weight_range[1])\n",
    "    \n",
    "    W_rec = torch.index_put(W_rec, ie_update_inds, ie_bounded_updates, accumulate=True)\n",
    "    W_rec = torch.index_put(W_rec, ei_update_inds, ei_bounded_updates, accumulate=True)\n",
    "     \n",
    "    \n",
    "    R = compute_piriform_response(h_bar_ff, W_rec, threshold_mult)\n",
    "    R_new = R\n",
    "    \n",
    "    if detach_grad:\n",
    "        # We want a new R response tensor which only has the previous weight update but not anything before that\n",
    "        W_rec = W_rec.detach()\n",
    "        R_new = compute_piriform_response(h_bar_ff, W_rec, threshold_mult)\n",
    "\n",
    "    if with_loss:\n",
    "        print(f\"IE over: {ie_over_weight}\")\n",
    "        print(f\"EI over: {ei_over_weight}\")\n",
    "        loss = loss_fn(R, lambda_corr, lambda_mu, lambda_var, lambda_sp)\n",
    "        overload = ie_over_weight + ei_over_weight\n",
    "    else:\n",
    "        loss = 0\n",
    "        overload = 0\n",
    "    \n",
    "    return loss, overload, W_rec, R_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22297cdeba801b81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.275753Z",
     "start_time": "2024-08-01T17:46:24.267072Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_update_inds(post, pre, W):\n",
    "    weights_slice = W[post[0]:post[1], pre[0]:pre[1]]\n",
    "    inds = torch.nonzero(weights_slice, as_tuple=True)\n",
    "    update_inds = (inds[0] + post[0], inds[1] + pre[0])\n",
    "    \n",
    "    return update_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70c09c7202ebd3f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:25.275720Z",
     "start_time": "2024-08-01T17:46:24.263582Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mult = 100\n",
    "w_ie = 0.5\n",
    "ie_max_weight = mult * w_ie\n",
    "ie_min_weight = 0\n",
    "\n",
    "w_ei = -0.2\n",
    "ei_max_weight = 0\n",
    "ei_min_weight = mult * w_ei\n",
    "\n",
    "ie_post = (num_e, num_neurons)\n",
    "ie_pre = (0, num_e)\n",
    "\n",
    "ei_post = (0, num_e)\n",
    "ei_pre = (num_e, num_neurons)\n",
    "\n",
    "def test_regime(ie_val, ei_val):\n",
    "    runs = 100\n",
    "    loss_ratios = torch.empty((runs,))\n",
    "    for i in range(runs):\n",
    "        with torch.no_grad():\n",
    "            I = correlated_mitral_activity()\n",
    "            hbar_ff = compute_feedforward_activity(I)\n",
    "            W = compute_initial_recurrent_weights()\n",
    "            R = compute_piriform_response(hbar_ff, W, 0)\n",
    "            initial_loss = loss_fn(R, 1, 0, 0, 0, do_print=False)\n",
    "            ie_update_inds = get_update_inds(ie_post, ie_pre, W)\n",
    "            ei_update_inds = get_update_inds(ei_post, ei_pre, W)\n",
    "            W[ie_update_inds] = ie_val\n",
    "            W[ei_update_inds] = ei_val\n",
    "            R_0 = compute_piriform_response(hbar_ff, W, 0)\n",
    "            final_loss = loss_fn(R_0, 1, 0, 0, 0, do_print=False)\n",
    "        \n",
    "        total_loss = final_loss / initial_loss\n",
    "        #print(f\"Loss Ratio: {total_loss.item()}\")\n",
    "        loss_ratios[i] = total_loss\n",
    "        \n",
    "    plt.hist(loss_ratios, bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9cdbdcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Both zero\n",
    "test_regime(0., 0.)\n",
    "plt.title(\"Loss Ratios - both 0\")\n",
    "plt.show()\n",
    "# IE cranked\n",
    "test_regime(ie_max_weight, w_ei)\n",
    "plt.title(\"Loss Ratios - E->I cranked\")\n",
    "plt.show()\n",
    "# EI cranked\n",
    "test_regime(w_ie, ei_min_weight)\n",
    "plt.title(\"Loss Ratios - I->E cranked\")\n",
    "plt.show()\n",
    "# Both cranked\n",
    "test_regime(ie_max_weight, ei_min_weight)\n",
    "plt.title(\"Loss Ratios - both cranked\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70723f2b6444f1b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T18:20:56.821190Z",
     "start_time": "2024-08-01T18:20:56.742882Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of independent \"sniffs\" of the 16 odors\n",
    "n_inner = 10\n",
    "# Number of different realizations of the odor sniffing process\n",
    "n_outer = 1000\n",
    "\n",
    "# TODO change back to -3 if too noisy\n",
    "plasticity_rate = 1e-1\n",
    "# Same plasticity rate for EI and IE\n",
    "plasticity_ie = plasticity_ei = plasticity_rate\n",
    "\n",
    "# TODO experiment w/ diff gradient tracking numbers\n",
    "# Number of inner epochs between model updates, n_update <= n_inner\n",
    "n_update = 10\n",
    "# Number of inner epochs across which the gradient is tracked (right now we detach the gradient after each inner epoch), n_track <= n_inner\n",
    "n_track = n_update\n",
    "\n",
    "# n_track = n_update to test formulation where we track the gradient across a subset of the inner epochs and update the model\n",
    "# If n_update > n_track, the model will have multiple \"gradient\" paths of loss accumulated: ex. inner epochs 1-5 and a separate branch of 6-10\n",
    "# If n_update < n_track, it doesn't matter b/c the model will truncate the history past its previous update since the gradient is zeroed\n",
    "\n",
    "# Number of standard deviations from mean, we are trying 0 b/c 1 and 2 is too sparse\n",
    "threshold_multiplier = 0\n",
    "\n",
    "# TODO for now go to simple formulation, no weight decay\n",
    "weight_decay = 0\n",
    "# How much to weight each of the regularization terms\n",
    "# Sparsity = 1000 doesn't improve loss ratios\n",
    "# Sparsity = 100, 500 epochs, loss ratios 1.0-1.8, blows up sparsity\n",
    "# Go back to 500 epochs no sparsity reg, w/ new nan clipping formulation\n",
    "lambda_corr, lambda_mu, lambda_var, lambda_sp = 1, 0, 0, 0\n",
    "\n",
    "ie_model = create_model()\n",
    "ie_model.to(gpu)\n",
    "ei_model = create_model()\n",
    "ei_model.to(gpu)\n",
    "\n",
    "\n",
    "mult = 100\n",
    "w_ie = 0.5\n",
    "ie_max_weight = mult * w_ie\n",
    "ie_min_weight = 0\n",
    "\n",
    "w_ei = -0.2\n",
    "ei_max_weight = 0\n",
    "ei_min_weight = mult * w_ei\n",
    "\n",
    "ie_post = (num_e, num_neurons)\n",
    "ie_pre = (0, num_e)\n",
    "\n",
    "ei_post = (0, num_e)\n",
    "ei_pre = (num_e, num_neurons)\n",
    "\n",
    "def train_model():\n",
    "    #torch.autograd.set_detect_anomaly(True)\n",
    "    \n",
    "    # TODO try LR -3\n",
    "    # TODO try w/o momentum\n",
    "    ie_optim = optim.SGD(ie_model.parameters(), lr=1e-3, momentum=0)\n",
    "    ei_optim = optim.SGD(ei_model.parameters(), lr=1e-3, momentum=0)\n",
    "    \n",
    "    updates_per_outer = n_inner // n_update\n",
    "    num_losses = int(updates_per_outer * n_outer)\n",
    "    losses = torch.empty(size=(num_losses,))\n",
    "    # batch every 20 (ex. tried 50 and was slightly more noisy (but w/ similar mean))\n",
    "    # batch_every = 20\n",
    "    # batch_loss = 0\n",
    "    \n",
    "    for outer_e in range(n_outer):\n",
    "        i = correlated_mitral_activity()\n",
    "        hbar_ff = compute_feedforward_activity(i)\n",
    "        \n",
    "        W_initial = compute_initial_recurrent_weights()\n",
    "        W = W_initial.clone().to(gpu)\n",
    "        W.requires_grad_(True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            ie_update_inds = get_update_inds(ie_post, ie_pre, W)\n",
    "            ei_update_inds = get_update_inds(ei_post, ei_pre, W)\n",
    "            \n",
    "            clamp_min = torch.zeros_like(W)\n",
    "            clamp_min[ei_update_inds] = ei_min_weight\n",
    "            clamp_min[ie_update_inds] = ie_min_weight\n",
    "            clamp_max = torch.zeros_like(W)\n",
    "            clamp_max[ie_update_inds] = ie_max_weight\n",
    "            clamp_max[ei_update_inds] = ei_max_weight\n",
    "            weight_range = (clamp_min, clamp_max)\n",
    "        \n",
    "        # Initial neuron responses\n",
    "        R = compute_piriform_response(hbar_ff, W, threshold_multiplier)\n",
    "        \n",
    "        # TODO look at loss ratios when we set weights to 0 (so the responses converge to the feedforward input value)\n",
    "        # Intuition: should do worse at decorrelation (or maybe nothing)\n",
    "        # If it does do worse, then there's an error in how we compute losses, if it doesn't do anything, the loss is being computed correctly\n",
    "        # Check intuition of cranking up E->I and I->E to max value (for the update inds) and see what losses are like\n",
    "        # - First only increase E to I, then only I to E, then both\n",
    "        for i in range(1, n_inner + 1):\n",
    "            with_loss = False\n",
    "            detach_grad = False\n",
    "            if i % n_update == 0:\n",
    "                with_loss = True\n",
    "                print(f\"Outer epoch {outer_e}, Inner epoch {i}, Loss: \\t\", end=\"\")\n",
    "            if i % n_track == 0:\n",
    "                detach_grad = True\n",
    "            \n",
    "            loss, overload, W, R = loss_after_odors(ie_model, ei_model, ie_update_inds, ei_update_inds, W, R, hbar_ff, threshold_multiplier, plasticity_ie, plasticity_ei, weight_decay, weight_range, lambda_corr, lambda_mu, lambda_var, lambda_sp, detach_grad=detach_grad, with_loss=with_loss)\n",
    "            \n",
    "            if with_loss:\n",
    "                final_loss = loss\n",
    "\n",
    "                R_initial = compute_piriform_response(hbar_ff, W_initial, threshold_multiplier)\n",
    "                initial_loss = loss_fn(R_initial, lambda_corr, lambda_mu, lambda_var, lambda_sp, do_print=False)\n",
    "                total_loss = final_loss / initial_loss\n",
    "                #total_loss += overload\n",
    "                print(f\"Loss ratio: {total_loss}\")\n",
    "                losses[(outer_e * updates_per_outer)  + (i // n_update) - 1] = total_loss.item()\n",
    "                total_loss.backward()\n",
    "                #batch_loss += total_loss\n",
    "                # ie_grad = torch.nn.utils.clip_grad_norm_(ie_model.parameters(), max_norm = 1e5)\n",
    "                # ei_grad = torch.nn.utils.clip_grad_norm_(ei_model.parameters(), max_norm = 1e5)\n",
    "                # print(f\"ie model grad: {ie_grad}\")\n",
    "                # print(f\"ei model grad: {ei_grad}\")\n",
    "                ie_optim.step()  \n",
    "                ei_optim.step()\n",
    "                ie_optim.zero_grad()\n",
    "                ei_optim.zero_grad()\n",
    "            \n",
    "        # if outer_e % batch_every == 0:\n",
    "        #     batch_loss.backward()   \n",
    "        #     ie_optim.step()\n",
    "        #     ei_optim.step()\n",
    "        #     ie_optim.zero_grad()\n",
    "        #     ei_optim.zero_grad()\n",
    "        #     batch_loss = 0\n",
    "                \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e34a7ed21ff8c903",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T18:21:43.717186Z",
     "start_time": "2024-08-01T18:20:57.000500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.07 GiB. GPU 0 has a total capacity of 11.76 GiB of which 101.88 MiB is free. Process 67292 has 6.81 GiB memory in use. Including non-PyTorch memory, this process has 4.77 GiB memory in use. Of the allocated memory 3.80 GiB is allocated by PyTorch, and 861.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m losses \u001b[39m=\u001b[39m train_model()\n",
      "Cell \u001b[0;32mIn[27], line 105\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m n_track \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    103\u001b[0m     detach_grad \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m loss, overload, W, R \u001b[39m=\u001b[39m loss_after_odors(ie_model, ei_model, ie_update_inds, ei_update_inds, W, R, hbar_ff, threshold_multiplier, plasticity_ie, plasticity_ei, weight_decay, weight_range, lambda_corr, lambda_mu, lambda_var, lambda_sp, detach_grad\u001b[39m=\u001b[39;49mdetach_grad, with_loss\u001b[39m=\u001b[39;49mwith_loss)\n\u001b[1;32m    107\u001b[0m \u001b[39mif\u001b[39;00m with_loss:\n\u001b[1;32m    108\u001b[0m     final_loss \u001b[39m=\u001b[39m loss\n",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m, in \u001b[0;36mloss_after_odors\u001b[0;34m(ie_model, ei_model, ie_update_inds, ei_update_inds, W_rec, R_current, h_bar_ff, threshold_mult, plasticity_ie, plasticity_ei, weight_decay_rate, weight_range, lambda_corr, lambda_mu, lambda_var, lambda_sp, detach_grad, with_loss)\u001b[0m\n\u001b[1;32m      4\u001b[0m W_rec\u001b[39m.\u001b[39mrequires_grad_(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[39m# TODO new paradigm: computing updates across odors and between models in parallel\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# TODO regularize by penalizing high model update?\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m ie_model_updates, ei_model_updates \u001b[39m=\u001b[39m compute_updates(R_current, (ie_model, ei_model), (ie_update_inds, ei_update_inds))\n\u001b[1;32m     10\u001b[0m \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m#     val_tensor = ((1 - plasticity_rate * weight_decay_rate) * W_rec[update_inds]) + updates + (plasticity_rate * odor_update)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m#     condition = torch.logical_and(torch.gt(val_tensor, min_weight), torch.le(val_tensor, max_weight))\u001b[39;00m\n\u001b[1;32m     14\u001b[0m ie_updates \u001b[39m=\u001b[39m plasticity_ie \u001b[39m*\u001b[39m (ie_model_updates \u001b[39m-\u001b[39m weight_decay_rate \u001b[39m*\u001b[39m W_rec[ie_update_inds])\n",
      "Cell \u001b[0;32mIn[18], line 10\u001b[0m, in \u001b[0;36mcompute_updates\u001b[0;34m(R, models, update_inds)\u001b[0m\n\u001b[1;32m      8\u001b[0m presyn_responses \u001b[39m=\u001b[39m R[update_inds[i][\u001b[39m1\u001b[39m], :]\n\u001b[1;32m      9\u001b[0m model_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(tensors\u001b[39m=\u001b[39m(presyn_responses, postsyn_responses), dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m updates_per_odor \u001b[39m=\u001b[39m models[i](model_input)\n\u001b[1;32m     11\u001b[0m model_updates \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(updates_per_odor, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39msqueeze(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m all_updates\u001b[39m.\u001b[39mappend(model_updates)\n",
      "File \u001b[0;32m~/Piriform-Cortex-Plasticity/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Piriform-Cortex-Plasticity/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Piriform-Cortex-Plasticity/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    220\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Piriform-Cortex-Plasticity/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Piriform-Cortex-Plasticity/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Piriform-Cortex-Plasticity/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:104\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/Piriform-Cortex-Plasticity/venv/lib/python3.10/site-packages/torch/nn/functional.py:1500\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu_(\u001b[39minput\u001b[39m)\n\u001b[1;32m   1499\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m   1501\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.07 GiB. GPU 0 has a total capacity of 11.76 GiB of which 101.88 MiB is free. Process 67292 has 6.81 GiB memory in use. Including non-PyTorch memory, this process has 4.77 GiB memory in use. Of the allocated memory 3.80 GiB is allocated by PyTorch, and 861.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "losses = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8aabaa70054798",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:56.960642Z",
     "start_time": "2024-08-01T17:46:56.958505Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    plt.plot(torch.arange(losses.shape[0]), losses)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss ratio\")\n",
    "    plt.title(\"Loss ratio per realization over time\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3843b2195b086d5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.959377Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = correlated_mitral_activity()\n",
    "hbar_ff = compute_feedforward_activity(i)\n",
    "W_random = compute_initial_recurrent_weights()\n",
    "R_random = compute_piriform_response(hbar_ff, W_random, threshold_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da719c5a4a5ebbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:56.976483Z",
     "start_time": "2024-08-01T17:46:56.961173Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stats at initialization\n",
    "mu_familiar_0 = torch.mean(R_random[:num_e, familiar_inds], dim=1)\n",
    "sig_familiar_0 = torch.var(R_random[:num_e, familiar_inds], dim=1)\n",
    "mu_novel_0 = torch.mean(R_random[:num_e, novel_inds], dim=1)\n",
    "sig_novel_0 = torch.var(R_random[:num_e, novel_inds], dim=1)\n",
    "#print(f\"Initialization: \\nFamiliar -  mean: {mu_familiar_0}, var: {sig_familiar_0}\\nNovel -  mean: {mu_novel_0}, var: {sig_novel_0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67971e29f9bb692",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.962883Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R_random = R_random.to(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aea9b6d1ff27717",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.964663Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     22\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_inner):\n\u001b[0;32m---> 23\u001b[0m         _, W_plastic, R_plastic \u001b[39m=\u001b[39m loss_after_odors(ie_model, ei_model, ie_update_inds, ei_update_inds, W_plastic, R_plastic, hbar_ff, threshold_multiplier, plasticity_ie, plasticity_ei, weight_decay, weight_range, lambda_corr, lambda_mu, lambda_var, lambda_sp, detach_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, with_loss\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m         W_tracked[i, :, \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m W_plastic[ie_update_inds][ie_track_inds]\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m     25\u001b[0m         W_tracked[i, :, \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m W_plastic[ei_update_inds][ei_track_inds]\u001b[39m.\u001b[39mdetach()\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "W_plastic = W_random.detach().clone()\n",
    "R_plastic = R_random.detach().clone()\n",
    "with torch.no_grad():\n",
    "    ie_update_inds = get_update_inds(ie_post, ie_pre, W_plastic)\n",
    "    ei_update_inds = get_update_inds(ei_post, ei_pre, W_plastic)\n",
    "    clamp_min = torch.zeros_like(W_plastic)\n",
    "    clamp_min[ei_update_inds] = ei_min_weight\n",
    "    clamp_min[ie_update_inds] = ie_min_weight\n",
    "    clamp_max = torch.zeros_like(W_plastic)\n",
    "    clamp_max[ie_update_inds] = ie_max_weight\n",
    "    clamp_max[ei_update_inds] = ei_max_weight\n",
    "    weight_range = (clamp_min, clamp_max)\n",
    "\n",
    "\n",
    "# Number of weights from each group to track\n",
    "num_samples = 100\n",
    "W_tracked = torch.empty((n_inner, num_samples, 2))\n",
    "R_tracked = torch.empty((n_inner, num_i))\n",
    "ie_track_inds = torch.randint(0, len(ie_update_inds), size=(num_samples,))\n",
    "ei_track_inds = torch.randint(0, len(ei_update_inds), size=(num_samples,))\n",
    "with torch.no_grad():\n",
    "    for i in range(n_inner):\n",
    "        _, W_plastic, R_plastic = loss_after_odors(ie_model, ei_model, ie_update_inds, ei_update_inds, W_plastic, R_plastic, hbar_ff, threshold_multiplier, plasticity_ie, plasticity_ei, weight_decay, weight_range, lambda_corr, lambda_mu, lambda_var, lambda_sp, detach_grad=True, with_loss=False)\n",
    "        W_tracked[i, :, 0] = W_plastic[ie_update_inds][ie_track_inds].detach()\n",
    "        W_tracked[i, :, 1] = W_plastic[ei_update_inds][ei_track_inds].detach()\n",
    "        R_tracked[i, :] = torch.mean(R_plastic[num_e:, :], dim=1).detach()\n",
    "\n",
    "mu_familiar_f = torch.mean(R_plastic[:num_e, familiar_inds], dim=1)\n",
    "sig_familiar_f = torch.var(R_plastic[:num_e, familiar_inds], dim=1)\n",
    "mu_novel_f = torch.mean(R_plastic[:num_e, novel_inds], dim=1)\n",
    "sig_novel_f = torch.var(R_plastic[:num_e, novel_inds], dim=1)\n",
    "mu_novel_diff = mu_novel_f - mu_novel_0\n",
    "mu_familiar_diff = mu_familiar_f - mu_familiar_0\n",
    "sig_novel_diff = sig_novel_f - sig_novel_0\n",
    "sig_familiar_diff = sig_familiar_f - sig_familiar_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d6bbd72d52ab77",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.966417Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R_random = R_random.cpu()\n",
    "R_plastic = R_plastic.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630eb42d255674cd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.968115Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(R_tracked)\n",
    "plt.title(\"I responses across inner epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddea879c3b9927e2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.970104Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at how weights evolve over the course of inner epoch, for a random realization\n",
    "# Store a random set of 10 weights and see how the 10 weights change over the course of the iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd48d9b5cdbe58",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.971685Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)\n",
    "    ax1.hist(torch.flatten(R_random[:num_e]), density=True, label=\"E responses\")\n",
    "    ax1.hist(torch.flatten(R_random[num_e:]), density=True, label=\"I responses\")\n",
    "    ax1.set_title(\"Before plasticity\")\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.hist(torch.flatten(R_plastic[:num_e]), density=True, label=\"E responses\")\n",
    "    ax2.hist(torch.flatten(R_plastic[num_e:]), density=True, label=\"I responses\")\n",
    "    ax2.set_title(\"After plasticity\")\n",
    "    ax2.legend()\n",
    "    fig.suptitle(\"Responses\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f7a48ffa1db260",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.973328Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R_random[num_e:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815a783a635f96f3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.975049Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO figure out why I responses keep getting blown up to 0\n",
    "R_plastic[num_e:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2901f2e35c4e550",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:56.986239Z",
     "start_time": "2024-08-01T17:46:56.976720Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(W_plastic[ei_update_inds].cpu().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af71d4a512bc4881",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.978392Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(W_plastic[ie_update_inds].cpu().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547affea0c66ded8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.979980Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO model is learning to set all E->I weights to 0, and that's causing I responses to go to 0, then I->E weights can't do anything to fix that\n",
    "torch.unique((W_plastic[ie_update_inds].cpu().flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e970014f84261189",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.981629Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)\n",
    "    sparsities_0 = sparsity_per_odor(R_random)\n",
    "    spars_novel = sparsities_0[novel_inds]\n",
    "    spars_familiar = sparsities_0[familiar_inds]\n",
    "    ax1.hist(spars_novel, density=True, label=\"Novel\")\n",
    "    ax1.hist(spars_familiar, density=True, label=\"Familiar\")\n",
    "    ax1.set_title(\"Before plasticity\")\n",
    "    ax1.legend()\n",
    "    \n",
    "    sparsities_f = sparsity_per_odor(R_plastic)\n",
    "    spars_novel = sparsities_f[novel_inds]\n",
    "    spars_familiar = sparsities_f[familiar_inds]\n",
    "    ax2.hist(spars_novel, density=True, label=\"Novel\")\n",
    "    ax2.hist(spars_familiar, density=True, label=\"Familiar\")\n",
    "    ax2.set_title(\"After plasticity\")\n",
    "    ax2.legend()\n",
    "    fig.suptitle(\"Sparsity per odor\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a68603cd329249b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.983228Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def verification_set(ie_model, ei_model, runs=10):\n",
    "    corrs = torch.empty((runs,))\n",
    "    ratios = torch.empty((runs,))\n",
    "    spars_change = torch.empty((runs,))\n",
    "    for i in range(runs):\n",
    "        I_ff = correlated_mitral_activity()\n",
    "        hbar_ff = compute_feedforward_activity(I_ff)\n",
    "        W_random = compute_initial_recurrent_weights()\n",
    "        R_random = compute_piriform_response(hbar_ff, W_random, threshold_multiplier)\n",
    "        _, initial_corr = odor_corrs(R_random)\n",
    "        spars_initial = sparsity_per_odor(R_random)\n",
    "        initial_spars_diff = torch.abs(torch.mean(spars_initial[novel_inds]) - torch.mean(spars_initial[familiar_inds]))\n",
    "        \n",
    "        ie_update_inds = get_update_inds(ie_post, ie_pre, W_random)\n",
    "        ei_update_inds = get_update_inds(ei_post, ei_pre, W_random)\n",
    "        \n",
    "        for _ in range(n_inner):\n",
    "            _, W_random, R_random = loss_after_odors(ie_model, ei_model, ie_update_inds, ei_update_inds, W_random, R_random, hbar_ff, threshold_multiplier, plasticity_ie, plasticity_ei, weight_decay, weight_range, lambda_corr, lambda_mu, lambda_var, lambda_sp, detach_grad=True, with_loss=False)\n",
    "        \n",
    "        _, final_corr = odor_corrs(R_random)\n",
    "        ratio = final_corr / initial_corr\n",
    "        spars_final = sparsity_per_odor(R_random)\n",
    "        # Plot actual difference in the sparsity number, not the percent change ratio\n",
    "        # - Also see whether \n",
    "        final_spars_diff = torch.abs(torch.mean(spars_final[novel_inds]) - torch.mean(spars_final[familiar_inds]))\n",
    "        \n",
    "        print(f\"Corr: {initial_corr} -> {final_corr}, Sparsity: {initial_spars_diff} -> {final_spars_diff}, Loss Ratio: {ratio}\")\n",
    "        corrs[i] = final_corr.item()\n",
    "        ratios[i] = ratio.item()\n",
    "        spars_change[i] = (((final_spars_diff - initial_spars_diff) / initial_spars_diff) * 100).item()\n",
    "        \n",
    "    return corrs, ratios, spars_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bafcc0031d6f22",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.984704Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    corrs, ratios, spars_change = verification_set(ie_model, ei_model, runs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfae243066bddc4c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.986194Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(ratios, bins=20)\n",
    "plt.title(\"Loss ratios\")\n",
    "plt.show()\n",
    "plt.hist(spars_change, bins=20)\n",
    "plt.title(\"Percent change in sparsity per odor for novel vs. familiar families\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1cf70906cd0175",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.987518Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spars_change[spars_change < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5279dce2095c309d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.988670Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# version = \"6\"\n",
    "# ie_path = f\"./joint_models/ie_models/ie_model_{version}\"\n",
    "# torch.save(ie_model.state_dict(), ie_path)\n",
    "# ei_path = f\"./joint_models/ei_models/ei_model_{version}\"\n",
    "# torch.save(ei_model.state_dict(), ei_path)\n",
    "\n",
    "# Model 2 - loss ratios between 0.75 and 1, most sparsity changes within 100%\n",
    "# Model 3 - loss ratios between 0.94 and 1.04, reduces sparsity close to 100% (but has NaN values) \n",
    "# Model 4 - reduces sparsity close to 100%, loss ratios between 0.85 and 1 (basically tries to set weights to 0)\n",
    "# Model 5 - loss ratios between 0.9 and 1.1, most sparsity changes go to 0 (negative 100% sparsity change)\n",
    "\n",
    "# Interesting result from model 1 - tries to set all weights to 0\n",
    "#ie_model = create_model()\n",
    "#ie_model.load_state_dict(torch.load(ie_path))\n",
    "#ei_model = create_model()\n",
    "#ei_model.load_state_dict(torch.load(ei_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cb8ceeefdbfa5a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.990202Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_colormap(model, type=\"ie\"):\n",
    "    num_ticks = 100\n",
    "    E_min, E_max = torch.min(R_plastic[:num_e, :]), torch.max(R_plastic[:num_e, :])\n",
    "    I_min, I_max = torch.min(R_plastic[num_e:, :]), torch.max(R_plastic[num_e:, :])\n",
    "    E_vals = torch.linspace(E_min, E_max, num_ticks)\n",
    "    I_vals = torch.linspace(I_min, I_max, num_ticks)\n",
    "    E_coords, I_coords = torch.meshgrid(E_vals, I_vals, indexing=\"ij\")\n",
    "    R_plot = 0\n",
    "    if type == \"ie\":\n",
    "        R_plot = torch.stack((E_coords.flatten(), I_coords.flatten()), dim=1)\n",
    "    elif type == \"ei\":\n",
    "        R_plot = torch.stack((I_coords.flatten(), E_coords.flatten()), dim=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        plasticity_vals = model(R_plot.to(gpu)).squeeze(0).cpu()\n",
    "        \n",
    "    plot = plt.scatter(R_plot[:, 0], R_plot[:, 1], c=plasticity_vals, cmap='rainbow')\n",
    "    clrbar = plt.colorbar(plot)\n",
    "    clrbar.set_label('Model plasticity')\n",
    "    plt.xlabel(\"E responses\")\n",
    "    plt.ylabel(\"I responses\")\n",
    "        \n",
    "    return E_min, E_max, I_min, I_max, R_plot, plasticity_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c28c037048e3b5a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.991543Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def fit_model(model, type=\"ie\", degree=3):\n",
    "    E_min, E_max, I_min, I_max, R_plot, plasticity_vals = make_colormap(model, type)\n",
    "    \n",
    "\n",
    "    std = 2 # Take data within 2 std of responses mean\n",
    "    mu_e = torch.mean(torch.flatten(R_plastic[:num_e].cpu()))\n",
    "    sig_e = torch.std(torch.flatten(R_plastic[:num_e].cpu()))\n",
    "    mu_i = torch.mean(torch.flatten(R_plastic[num_e:].cpu()))\n",
    "    sig_i = torch.std(torch.flatten(R_plastic[num_e:].cpu()))\n",
    "    e_train_bounds = (torch.max(E_min, mu_e - std*sig_e), torch.min(E_max, mu_e + std*sig_e))\n",
    "    i_train_bounds = (torch.max(I_min, mu_i - std*sig_i), torch.min(I_max, mu_i + std*sig_i))\n",
    "    \n",
    "    reg = Pipeline([('poly', PolynomialFeatures(degree=degree)),\n",
    "                  ('linear', LinearRegression(fit_intercept=False))])\n",
    "    \n",
    "    e_inds = torch.logical_and(torch.ge(R_plot[:, 0], e_train_bounds[0]), torch.le(R_plot[:, 0], e_train_bounds[1]))\n",
    "    i_inds = torch.logical_and(torch.ge(R_plot[:, 1], i_train_bounds[0]), torch.le(R_plot[:, 1], i_train_bounds[1]))\n",
    "    b = torch.logical_and(e_inds, i_inds)\n",
    "    X = R_plot[b]\n",
    "    y = plasticity_vals[b].squeeze(0)\n",
    "    \n",
    "    reg = reg.fit(X, y)\n",
    "    # Exclude bias term\n",
    "    coefs = reg.named_steps['linear'].coef_[0][1:]\n",
    "    # How many terms to consider\n",
    "    take = 3\n",
    "    # Take largest magnitude terms\n",
    "    inds = np.argsort(np.abs(coefs))[-take:]\n",
    "\n",
    "    # Exclude bias term\n",
    "    term_list = reg.named_steps['poly'].powers_[1:, :]\n",
    "    terms = f\"[Pre, Post] Powers:\\n\"\n",
    "    for i in range(take - 1, -1, -1):\n",
    "        term = f\"{term_list[inds][i]}: {coefs[inds][i]}\\n\"\n",
    "        terms += term\n",
    "    \n",
    "    print(terms)\n",
    "    \n",
    "    preds = reg.predict(X).ravel()\n",
    "    return X, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ac6392aab0837e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.992481Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ie_X, ie_preds = fit_model(ie_model, type=\"ie\", degree=3)\n",
    "\n",
    "pred_plot = plt.scatter(ie_X[:, 0], ie_X[:, 1], c=ie_preds, cmap='rainbow')\n",
    "clrbar2 = plt.colorbar(pred_plot)\n",
    "clrbar2.set_label('Predicted')\n",
    "plt.title(\"E-I plasticity based on neural responses\")\n",
    "plt.xlabel(\"E responses\")\n",
    "plt.ylabel(\"I responses\")\n",
    "plt.show()\n",
    "\n",
    "ei_X, ei_preds = fit_model(ei_model, type=\"ei\", degree=3)\n",
    "\n",
    "pred_plot = plt.scatter(ei_X[:, 0], ei_X[:, 1], c=ei_preds, cmap='rainbow')\n",
    "clrbar2 = plt.colorbar(pred_plot)\n",
    "clrbar2.set_label('Predicted')\n",
    "plt.title(\"I-E plasticity based on neural responses\")\n",
    "plt.xlabel(\"I responses\")\n",
    "plt.ylabel(\"E responses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa938bb7961846a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T17:46:57.060814Z",
     "start_time": "2024-08-01T17:46:56.993604Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do a plot of rho_0 vs rho_final (for ex. 100 random initializations) to see whether the model can decorrelate odors\n",
    "# Even though potentiation is always positive for the set of responses, since we are doing E to I, increasing the connection strength effectively increases inhibition too, so it balances out\n",
    "# Not directly hebbian because that would mean there is some constant c*r_i*r_j, but when one of the responses is decreasing, the resulting potentiation doesn't decrease\n",
    "# Instead, it will be an a * r_i + b * r_j term\n",
    "# These terms come from the polynomial expansion of the function defined by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1fe6484d9fbc92",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.994660Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at statistics of E neurons (mean firing rate across odors, variance, etc) at initialization compared to after plasticity\n",
    "# Also look at sparsity - one across odors and another across neurons (sparsity is essentially 1 minus the square of the coefficient of variation)\n",
    "# We care mostly about the sparsity across neurons (ex between neurons) and what it would be between odors (should be similar between the familiar odors b/c that's where we applied the plasticity) and we also know what it's like between novel odors\n",
    "# We don't want a change in firing rate, because it should be same for novel and familiar odors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ed3911273faa8c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.995682Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pct_change = ((W_tracked[:, :, 0] - w_ie) / w_ie) * 100\n",
    "    plt.plot(pct_change)\n",
    "    plt.xlabel(\"Inner epochs\")\n",
    "    plt.ylabel(\"Weight percent change\")\n",
    "    plt.title(\"E-I weight change\")\n",
    "    plt.show()\n",
    "    \n",
    "    pct_change = ((W_tracked[:, :, 1] - w_ei) / w_ei) * 100\n",
    "    plt.plot(pct_change)\n",
    "    plt.xlabel(\"Inner epochs\")\n",
    "    plt.ylabel(\"Weight percent change\")\n",
    "    plt.title(\"I-E weight change\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804d8df91ba43350",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.996672Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_change = ((W_plastic[ie_update_inds].cpu() - w_ie) / w_ie) * 100\n",
    "plt.hist(W_change, density=True, bins=50)\n",
    "plt.title(\"E-I Percent weight change from initialization\")\n",
    "plt.show()\n",
    "\n",
    "W_change = ((W_plastic[ei_update_inds].cpu() - w_ei) / w_ei) * 100\n",
    "plt.hist(W_change, density=True, bins=50)\n",
    "plt.title(\"I-E Percent weight change from initialization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d07fb09871512a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.997803Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(mu_familiar_0.detach().cpu() - mu_novel_0.detach().cpu(), bins=50, label=\"Before\")\n",
    "plt.hist(mu_familiar_f.detach().cpu() - mu_novel_f.detach().cpu(), bins=50, label=\"After\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd90208f664a85ae",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.998838Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(mu_novel_diff, bins=50, label=\"Novel\")\n",
    "plt.hist(mu_familiar_diff, bins=50, label=\"Familiar\")\n",
    "plt.title(\"Difference in mean responses before and after plasticity\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecc851bc8f43f35",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:56.999877Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp_novel_0 = sparsity_per_neuron(R_random, novel_inds)\n",
    "sp_novel_f = sparsity_per_neuron(R_plastic, novel_inds)\n",
    "sp_familiar_0 = sparsity_per_neuron(R_random, familiar_inds)\n",
    "sp_familiar_f = sparsity_per_neuron(R_plastic, familiar_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee33d1ae62b6cd3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:57.000850Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    plt.hist(sp_novel_0, cumulative=True, bins=num_e, histtype=\"step\", label=\"Novel_0\")\n",
    "    plt.hist(sp_familiar_0, cumulative=True, bins=num_e, histtype=\"step\", label=\"Familiar_0\")\n",
    "    plt.hist(sp_novel_f, cumulative=True, bins=num_e, histtype=\"step\", label=\"Novel_f\")\n",
    "    plt.hist(sp_familiar_f, cumulative=True, bins=num_e, histtype=\"step\", label=\"Familiar_f\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ce75bd2a06f39a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:57.001884Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create scatter plot of odor correlation vs sparsity difference - odors that are highly positively correlated should have similar sparsities across neurons, and those that are highly negatively correlated should have different sparsities across neurons\n",
    "# Check - increase P' all the way to 16, and with lower correlations, there should be less variability between the sparsity for each odor\n",
    "# - would tell us how much the natural spread in sparsity is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd6174a08701aa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:57.003211Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. Re-run model w/ lower threshold (0 stdev above mean)\n",
    "# 2. Figure out percentage-wise how much the weights actually change (do a hist)\n",
    "# - if it's 1-2% it's too small, we want the weights to change 10-100%, the weights could even change 10-fold\n",
    "# 3. Add metrics to training function - automatically compute sparsity etc (also look at the sparsity between odors, not just the sparsity between neurons, see if it changes for novel vs familiar)\n",
    "# Create bar plot for each number of odors, how many neurons respond to that number of odors (ideally, if we have a threshold of 0 stdev, most neurons should respond to ~4 odors, since on average a neuron will respond to half of the total odors, so 8 odors, and out of those, it should be equal between 4 novel and 4 familiar)\n",
    "# Hypothesis right now - weights aren't changing that much, so we can add more epoch_inner steps (since the gradient isn't blowing up)\n",
    "# Then, try removing plasticity ramp - keep 1e-3 (don't do epoch_inner increase and remove plasticity ramp at same time)\n",
    "# Goal: understand what mechanism the meta-learning discovered that makes correlations smaller (see whether it acts on sparsity etc)\n",
    "# Think of other metrics to quantify network behavior to understand change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e8808ab6eb092",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-01T17:46:57.004349Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f64f3bee69275d7dadabcd164c00bee7a237ebc40dc30e8b43706029d0d9fbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
